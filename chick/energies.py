from chick.utils.plot_utils import plot_2D
from chick.utils.types import Energy
from chick.projection import Projection

from propose.propose.poses.human36m import Human36mPose

from torch.distributions import Normal, MultivariateNormal, Laplace
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# proj = Projection.from_pretrained()

def gaussian_2d_energy(x_sample, x_2d, x_2d_std, center, camera, **kwargs) -> Energy:
    """
        Energy function for conditioning on a monocular 2D pose using a gaussian approximation. of the distribution.
        :param x_sample: The 3D pose sample generated by the model.
        :param x_2d: The 2D pose.
        :param center: The center of the 3D pose.
        :param camera: The camera used to project the 3D pose.
        :return: The energy of the sample.
        """
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = camera.proj2D(x_sample)

    _x_2d = x_2d.permute(0, 3, 1, 2).clone()

    dist = Normal(loc=_x_2d, scale=x_2d_std.clone())

    energy = -dist.log_prob(x_2d_projected).mean(-1).mean(-1).sum(-1)

    return {
        "train": energy,
    }


def full_gaussian_2d_energy(x_sample, dist, center, camera, plot=False, **kwargs) -> Energy:
    """
        Energy function for conditioning on a monocular 2D pose using a gaussian approximation. of the distribution.
        :param x_sample: The 3D pose sample generated by the model.
        :param x_2d: The 2D pose.
        :param center: The center of the 3D pose.
        :param camera: The camera used to project the 3D pose.
        :return: The energy of the sample.
        """
    # clip the values to be in the range -1, 1
    x_sample = torch.clamp(x_sample, -1, 1)

    x_sample[:, [0]] = x_sample[:, [0]] * 0
    x_sample = torch.cat((x_sample[:, :9], x_sample[:, 10:]), dim=1)
    x_sample = x_sample + center.T

    x_2d_projected = camera.proj2D(x_sample[..., 0])
    x_2d_projected = x_2d_projected - x_2d_projected[:, [0]]
    # x_gt_projected = x_gt_projected / 250 * 32
    x_2d_projected = x_2d_projected / x_2d_projected.std() * 32 / 3
    # x_2d = x_2d_projected.clone()

    # remove index 9 from x_2d_projected (the neck) as it is not observed
    # x_2d_projected = torch.cat((x_2d_projected[:, :9], x_2d_projected[:, 10:]), dim=1)
    # x_2d_projected = x_2d_projected
    # x_2d_projected *= -1
    # x_2d_projected = x_2d_projected[:, 1:]

    # print(x_2d_projected.shape, dist.loc.shape, dist.covariance_matrix.shape)

    # print('2d', x_2d_projected.mean(), x_2d_projected.std(), dist.loc.mean(), dist.loc.mean())

    # scale = x_2d_projected.std() / dist.loc.std()
    # x_2d_projected = x_2d_projected / 4
    # dist.loc = dist.loc
    # dist.covariance_matrix = dist.covariance_matrix / dist.loc.std()**2

    # print(x_2d_projected.shape, dist.loc.shape)

    x_2d_projected = x_2d_projected / x_2d_projected.std() * 32 / 3
    dist.loc = dist.loc / dist.loc.std() * 32 / 3

    error = ((x_2d_projected - dist.loc) ** 2)

    energy = (
        error.mean(-1).mean(-1)#.sum(-1)
    ) / 7000

    # print(energy.mean())

    # if plot:
    #     _2d = torch.cat((x_2d_projected[0, :9], torch.zeros_like(x_2d_projected[0, :1]), x_2d_projected[0, 9:]), dim=0)
    #     __2d = torch.cat((dist.loc[:9], torch.zeros_like(dist.loc[:1]), dist.loc[9:]), dim=0)
    #
    #     _2d = _2d / _2d.std()
    #     __2d = __2d / __2d.std()
    #     Human36mPose(-_2d.cpu().numpy()).plot()
    #     Human36mPose(-__2d.cpu().numpy()).plot()
    #     plt.savefig('x_2d_projected.png')
    #     plt.close()
    # print(energy.mean())
    # log_prob = dist.log_prob(x_2d_projected) # (num_samples, 16)
    # energy = -log_prob.mean(-1)#.mean(-1).sum(-1)
    # energy = energy * 1e-4

    # print(energy.mean())


    # pose_2d = dist.loc
    # insert the neck back in
    # pose_2d = torch.cat((pose_2d[:9], torch.zeros_like(pose_2d[:1]), pose_2d[9:]), dim=0)

    # Human36mPose(x_2d[0].squeeze().detach().cpu().numpy()/ 7).plot(plot_type='none', c='k', alpha=.1)
    # Human36mPose(pose_2d.squeeze().detach().cpu().numpy()).plot(plot_type='none', c='r')
    # MPIIPose(-og_pose.squeeze().detach().cpu().numpy()).plot(plot_type='none', c='g')
    # plt.axis('equal')
    # plt.savefig('test_energy.png')
    # plt.close()

    return {
        "train": energy,
    }


def fit_gaussian_2d_energy(x_sample, heatmap, center, camera, **kwargs) -> Energy:
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = camera.proj2D(x_sample)


    dist = fit_multivariate_normal(heatmap[0][0])
    print(dist.mean, dist.covariance_matrix)

def w_monocular_2d_energy(x_sample, x_2d, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = torch.clamp(x_sample, -1, 1)

    x_sample = x_sample + center.T

    x_2d_projected = camera.proj2D(x_sample[..., 0])
    x_2d_projected = x_2d_projected - x_2d_projected[:, [0]]
    # x_2d_projected = x_2d_projected / 7

    # remove index 9 from x_2d_projected (the neck) as it is not observed
    x_2d_projected = torch.cat((x_2d_projected[:, :9], x_2d_projected[:, 10:]), dim=1)

    energy = (
        ((x_2d_projected - x_2d) ** 2).mean(-1).mean(-1).sum(-1)
    )

    return {
        "train": energy,
    }

def monocular_2d_energy(x_sample, x_2d, center, camera, mpii=False, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = camera.proj2D(x_sample)

    _x_2d = x_2d.permute(0, 3, 1, 2).clone()

    if mpii:
        # delete index 9 from the poses
        x_2d_projected = torch.cat([x_2d_projected[:, :, :9, :], x_2d_projected[:, :, 10:, :]], dim=2)
        _x_2d = torch.cat([_x_2d[:, :, :9, :], _x_2d[:, :, 10:, :]], dim=2)

    energy = (
        ((x_2d_projected - _x_2d) ** 2).mean(-1).mean(-1).sum(-1)
    )

    return {
        "train": energy,
    }


def heatmap_energy(x_sample, heatmap, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)

    def batch_jacobian(f, x):
        f_sum = lambda x: torch.sum(f(x), axis=0)
        return torch.autograd.functional.jacobian(f_sum, x).permute(1, 2, 0)

    jacobioan = batch_jacobian(camera.proj2D, x_sample.squeeze()[1:, :])

    x_2d_projected = camera.proj2D(x_sample)

    heatmap = heatmap - heatmap.min() + 1e-6
    nll = -torch.log(heatmap)

    plt.imshow(nll.sum(dim=(0, 1)).detach().cpu().numpy())
    plt.colorbar()
    plt.savefig("dx.png")
    plt.close()

    dx = torch.stack(torch.gradient(nll, dim=(1, 2)), dim=-1)

    x_int = (x_2d_projected * 500 + 500).round().long()
    x_int = x_int[:, :, 1:]  # drop the hip keypoint
    x_int = x_int.clamp_(0, 999)

    update = dx[0, torch.arange(16), x_int[..., 0], x_int[..., 1]]

    print(update.mean())

    # tensor dot between jacobian and update (jacobian is 16x2x3, update is 16x2) -> 16x3
    update = jacobioan @ update.squeeze().unsqueeze(-1)
    update = update.squeeze()
    # add zeros for the hip keypoint
    update = torch.cat([torch.zeros_like(update[:1]), update], dim=0)

    return {
        "train": update,
    }

def learned_2d_energy(x_sample, x_2d, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample# - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = proj(x_sample)

    # print(x_2d.shape)
    x_2d = x_2d - x_2d[:, 0:1, :, :]
    _x_2d = x_2d.permute(0, 3, 1, 2).clone()

    energy = (
        ((x_2d_projected - _x_2d) ** 2).mean(-1).mean(-1).sum(-1)
    )

    # print(energy)

    return {
        "train": energy,
    }

def inpaint_2d_energy(x_sample, x_2d, center, **kwargs):
    return {
        "input_2D": x_2d + center.unsqueeze(0).permute(0, 1, 3, 2)[..., [0, 1], :],
    }


energies = {
    "monocular": monocular_2d_energy,
    "gaussian": gaussian_2d_energy,
    "full_gaussian": full_gaussian_2d_energy,
    "w_monocular": w_monocular_2d_energy,
    "heatmap": heatmap_energy,
    "learned": learned_2d_energy,
    "inpaint": inpaint_2d_energy,
}
