import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.distributions import Laplace, MultivariateNormal, Normal, Distribution

from platypose.projection import Projection
from platypose.utils.plot_utils import plot_2D
from platypose.utils.types import Energy
from propose.propose.poses.human36m import Human36mPose

# proj = Projection.from_pretrained()


def gaussian_2d_energy(x_sample, x_2d, x_2d_std, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose using a gaussian approximation. of the distribution.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = camera.proj2D(x_sample)

    _x_2d = x_2d.permute(0, 3, 1, 2).clone()

    dist = Normal(loc=_x_2d, scale=x_2d_std.clone())

    energy = -dist.log_prob(x_2d_projected).mean(-1).mean(-1).sum(-1)

    return {
        "train": energy,
    }


def full_gaussian_2d_energy(
    x_sample, dist, center, camera, plot=False, **kwargs
) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose using a gaussian approximation. of the distribution.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    # clip the values to be in the range -1, 1
    x_sample = torch.clamp(x_sample, -1, 1)

    x_sample[:, [0]] = x_sample[:, [0]] * 0
    x_sample = torch.cat((x_sample[:, :9], x_sample[:, 10:]), dim=1)
    x_sample = x_sample + center.T

    x_2d_projected = camera.proj2D(x_sample[..., 0])
    x_2d_projected = x_2d_projected - x_2d_projected[:, [0]]
    # x_gt_projected = x_gt_projected / 250 * 32
    x_2d_projected = x_2d_projected / x_2d_projected.std() * 32 / 3
    # x_2d = x_2d_projected.clone()

    # remove index 9 from x_2d_projected (the neck) as it is not observed
    # x_2d_projected = torch.cat((x_2d_projected[:, :9], x_2d_projected[:, 10:]), dim=1)
    # x_2d_projected = x_2d_projected
    # x_2d_projected *= -1
    # x_2d_projected = x_2d_projected[:, 1:]

    # print(x_2d_projected.shape, dist.loc.shape, dist.covariance_matrix.shape)

    # print('2d', x_2d_projected.mean(), x_2d_projected.std(), dist.loc.mean(), dist.loc.mean())

    # scale = x_2d_projected.std() / dist.loc.std()
    # x_2d_projected = x_2d_projected / 4
    # dist.loc = dist.loc
    # dist.covariance_matrix = dist.covariance_matrix / dist.loc.std()**2

    # print(x_2d_projected.shape, dist.loc.shape)

    x_2d_projected = x_2d_projected / x_2d_projected.std() * 32 / 3
    dist.loc = dist.loc / dist.loc.std() * 32 / 3

    error = (x_2d_projected - dist.loc) ** 2

    energy = (error.mean(-1).mean(-1)) / 7000  # .sum(-1)

    # print(energy.mean())

    # if plot:
    #     _2d = torch.cat((x_2d_projected[0, :9], torch.zeros_like(x_2d_projected[0, :1]), x_2d_projected[0, 9:]), dim=0)
    #     __2d = torch.cat((dist.loc[:9], torch.zeros_like(dist.loc[:1]), dist.loc[9:]), dim=0)
    #
    #     _2d = _2d / _2d.std()
    #     __2d = __2d / __2d.std()
    #     Human36mPose(-_2d.cpu().numpy()).plot()
    #     Human36mPose(-__2d.cpu().numpy()).plot()
    #     plt.savefig('x_2d_projected.png')
    #     plt.close()
    # print(energy.mean())
    # log_prob = dist.log_prob(x_2d_projected) # (num_samples, 16)
    # energy = -log_prob.mean(-1)#.mean(-1).sum(-1)
    # energy = energy * 1e-4

    # print(energy.mean())

    # pose_2d = dist.loc
    # insert the neck back in
    # pose_2d = torch.cat((pose_2d[:9], torch.zeros_like(pose_2d[:1]), pose_2d[9:]), dim=0)

    # Human36mPose(x_2d[0].squeeze().detach().cpu().numpy()/ 7).plot(plot_type='none', c='k', alpha=.1)
    # Human36mPose(pose_2d.squeeze().detach().cpu().numpy()).plot(plot_type='none', c='r')
    # MPIIPose(-og_pose.squeeze().detach().cpu().numpy()).plot(plot_type='none', c='g')
    # plt.axis('equal')
    # plt.savefig('test_energy.png')
    # plt.close()

    return {
        "train": energy,
    }


def fit_gaussian_2d_energy(x_sample, heatmap, center, camera, **kwargs) -> Energy:
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = camera.proj2D(x_sample)

    dist = fit_multivariate_normal(heatmap[0][0])
    print(dist.mean, dist.covariance_matrix)


def w_monocular_2d_energy(x_sample, x_2d, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = torch.clamp(x_sample, -1, 1)

    x_sample = x_sample + center.T

    x_2d_projected = camera.proj2D(x_sample[..., 0])
    x_2d_projected = x_2d_projected - x_2d_projected[:, [0]]
    # x_2d_projected = x_2d_projected / 7

    # remove index 9 from x_2d_projected (the neck) as it is not observed
    x_2d_projected = torch.cat((x_2d_projected[:, :9], x_2d_projected[:, 10:]), dim=1)

    energy = ((x_2d_projected - x_2d) ** 2).mean(-1).mean(-1).sum(-1)

    return {
        "train": energy,
    }


def monocular_2d_energy(x_sample, x_2d, center, camera, mpii=False, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    # x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    # x_sample = x_sample.permute(0, 3, 1, 2) # (num_samples, num_frames, num_joints, 3)
    x_sample = x_sample.reshape(1, 256, 17, 3).clone()
    # center = x_sample[:, :, :1, :].clone()
    # x_sample[:, :, 0, :] = 0
    # x_sample = x_sample + center

    # center = x_sample[:, :, :1, :].clone()
    # x_sample[:, :, 0, :] = 0
    # x_sample = x_sample + center

    x_2d_projected = camera.proj2D(x_sample)

    # Bones are rigid so their length should not change
    # d3_pose = Human36mPose(x_sample)
    # bone_lengths = d3_pose.bone_lengths # (num_samples, num_frames, num_bones)
    # bone_velocity = torch.pow(bone_lengths[:, 1:] - bone_lengths[:, :-1], 2).mean(-1).sum(-1)

    _x_2d = x_2d.clone()  # .permute(0, 3, 1, 2).clone()

    if mpii:
        # delete index 9 from the poses
        x_2d_projected = torch.cat(
            [x_2d_projected[:, :, :9, :], x_2d_projected[:, :, 10:, :]], dim=2
        )
        _x_2d = torch.cat([_x_2d[:, :, :9, :], _x_2d[:, :, 10:, :]], dim=2)

    # velocity_loss = torch.clip(torch.norm(x_sample[:, 1:] - x_sample[:, :-1], dim=-1).mean(-1).abs(), min=0.02)
    # print(velocity_loss[0])
    # print(acceleration_loss)

    # idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]
    # idxs = [0,1,2,3,4,5,26,27,28,29,30,31]
    # idxs = [0,1,2,3,4,5,6,7,8,24,25,26,27,28,29,30,31]
    # n_frames = x_2d_projected.shape[1]
    # idxs = torch.arange(n_frames)
    # idxs = torch.cat([idxs[:int(0.25 * n_frames)], idxs[-int(0.25 * n_frames):]])

    x_2d_projected = x_2d_projected  # [:, idxs]
    _x_2d = _x_2d  # [:, idxs]

    energy = (
        ((x_2d_projected - _x_2d) ** 2)
        .mean(-1)
        .mean(-1)
        .sum(-1)
        # + bone_velocity * 2e-2
    )  # + velocity_loss.amax(-1) * 1e-2

    print(energy.mean())

    return {
        "train": energy,
    }


def monocular_2d_energy_two_cams(
    x_sample, x_2d, x_2d_2, center, camera, camera2, mpii=False, **kwargs
) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    # x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    # x_sample = x_sample.permute(0, 3, 1, 2) # (num_samples, num_frames, num_joints, 3)
    x_sample = x_sample.reshape(1, 256, 17, 3).clone()
    # center = x_sample[:, :, :1, :].clone()
    # x_sample[:, :, 0, :] = 0
    # x_sample = x_sample + center

    # center = x_sample[:, :, :1, :].clone()
    # x_sample[:, :, 0, :] = 0
    # x_sample = x_sample + center

    x_2d_projected = camera.proj2D(x_sample)
    x_2d_projected_2 = camera2.proj2D(x_sample)

    # Bones are rigid so their length should not change
    # d3_pose = Human36mPose(x_sample)
    # bone_lengths = d3_pose.bone_lengths # (num_samples, num_frames, num_bones)
    # bone_velocity = torch.pow(bone_lengths[:, 1:] - bone_lengths[:, :-1], 2).mean(-1).sum(-1)

    _x_2d = x_2d.clone()  # .permute(0, 3, 1, 2).clone()
    _x_2d_2 = x_2d_2.clone()  # .permute(0, 3, 1, 2).clone()

    if mpii:
        # delete index 9 from the poses
        x_2d_projected = torch.cat(
            [x_2d_projected[:, :, :9, :], x_2d_projected[:, :, 10:, :]], dim=2
        )
        _x_2d = torch.cat([_x_2d[:, :, :9, :], _x_2d[:, :, 10:, :]], dim=2)

    # velocity_loss = torch.clip(torch.norm(x_sample[:, 1:] - x_sample[:, :-1], dim=-1).mean(-1).abs(), min=0.02)
    # print(velocity_loss[0])
    # print(acceleration_loss)

    # idxs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]
    # idxs = [0,1,2,3,4,5,26,27,28,29,30,31]
    # idxs = [0,1,2,3,4,5,6,7,8,24,25,26,27,28,29,30,31]
    # n_frames = x_2d_projected.shape[1]
    # idxs = torch.arange(n_frames)
    # idxs = torch.cat([idxs[:int(0.25 * n_frames)], idxs[-int(0.25 * n_frames):]])

    x_2d_projected = x_2d_projected  # [:, idxs]
    _x_2d = _x_2d  # [:, idxs]

    energy = ((x_2d_projected - _x_2d) ** 2).mean(-1).mean(-1).sum(-1) + (
        (x_2d_projected_2 - _x_2d_2) ** 2
    ).mean(-1).mean(-1).sum(-1)

    print(energy.mean())

    return {
        "train": energy,
    }

class ExponentialNDistribution(Normal):
    def __init__(self, n, *args, **kwargs):
        super(ExponentialNDistribution, self).__init__(*args, **kwargs)
        self.n = n

    def log_prob(self, value):
        if self._validate_args:
            self._validate_sample(value)
        return (
            -0.5 * (torch.abs(value - self.loc) / self.scale) ** self.n
        )

def multi_view_old(x_sample, x_2d, x_3d, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample.reshape(x_sample.shape[0], x_sample.shape[1], 17, 3).clone()

    # center = x_sample[:, :, :1, :].clone()
    # x_sample[:, :, 0, :] = 0
    # x_sample = x_sample + center

    # clip the values to be in the range -10, 10
    trajectory = x_sample[:, :, :1, :].clone()
    trajectory = torch.clamp(trajectory, -5, 5)

    # x_sample[:, :, 1:, :] = x_sample[:, :, 1:, :] + trajectory
    # x_sample[:, :, 1:, :] = x_sample[:, :, 1:, :] + x_sample[:, :, :1, :]
    # x_sample = x_sample - x_sample[:, :1, :1, :]
    # x_sample = torch.clamp(x_sample, -2, 2)
    # x_sample = x_sample - x_sample[:, :, :1]
    x_sample[:, :, 1:, :] = x_sample[:, :, 1:, :] + x_3d[:, :, :1, :]
    # x_sample[:, :, 0] = x_3d[:, :, 0]

    # compute the velocity of each joint
    vel = torch.norm(x_sample[:, 1:] - x_sample[:, :-1], dim=-1).abs().mean(-1)
    acceleration = torch.norm(vel[:, 1:] - vel[:, :-1], dim=-1).abs().mean(-1)
    mean_vel = vel.mean()
    mean_acceleration = acceleration.mean()

    x_2d_projected = [cam.proj2D(x_sample) for cam in camera]

    # x_2d = [x_gt - x_gt[:, :, :1] for x_gt in x_2d]
    # x_2d_projected = [x_gt - x_gt[:, :, :1] for x_gt in x_2d_projected]

    # fig = plt.figure()
    # Human36mPose(x_2d_projected[0].detach().cpu().numpy()).plot(ax=plt.gca(), plot_type="none", c="#f96113")
    # Human36mPose(x_2d[0].detach().cpu().numpy()).plot(ax=plt.gca(), plot_type="none", c="k")
    # plt.savefig("test.png")
    # plt.close()
    # exit()

    # dist = [ExponentialNDistribution(n=3, loc=d2, scale=torch.ones_like(d2) * 0.2) for d2 in x_2d]

    # energy = torch.stack([
    #     -d.log_prob(x_proj) for d, x_proj in zip(dist, x_2d_projected)
    # ], dim=0)

    energy = torch.stack(
        [((x_proj - x_gt) ** 2) for x_proj, x_gt in zip(x_2d_projected, x_2d)], dim=0
    )

    # energy[0, :, 64:192] = 0
    # energy[1, :, :, 1:4] = 0
    # energy[1, :, :, 4:7] = 0

    energy = energy.mean(-1).mean(-1).sum(-1).sum(0)# + 0.5 * mean_vel

    return {
        "train": energy,
    }

def multi_view(x_sample, x_2d, x_3d, camera, scale, mpii=False, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample.reshape(x_sample.shape[0], x_sample.shape[1], 17, 3).clone()

    x_sample = x_sample + x_3d[:, :, :1, :]

    x_2d_projected = torch.stack([cam.proj2D(x_sample) for cam in camera], dim=0)

    if mpii:
        # delete index 9 from the poses
        x_2d_projected = torch.cat(
            [x_2d_projected[..., :9, :], x_2d_projected[..., 10:, :]], dim=-2
        )
        x_2d = torch.cat([x_2d[..., :9, :], x_2d[..., 10:, :]], dim=-2)

    # fig = plt.figure()
    # Human36mPose(x_2d_projected[0, 0].detach().cpu().numpy()).plot(ax=plt.gca(), plot_type="none", c="#f96113")
    # Human36mPose(x_2d[0].detach().cpu().numpy()).plot(ax=plt.gca(), plot_type="none", c="k")
    # plt.savefig("test.png")
    # plt.close()
    # exit()

    # dist = Normal(loc=x_2d, scale=scale.unsqueeze(-1).repeat(1, 1, 1, 1, 2).cuda())
    #
    # energy = -dist.log_prob(x_2d_projected).mean(-1).mean(-1).sum(-1)
    # return energy

    # print(x_2d_projected.shape, x_2d.shape, scale.shape)
    # a = x_2d_projected[0]
    # b = x_2d[0]
    # ms = (a - b)**2
    # ms = ms.unsqueeze(-2)
    # print(ms.shape, scale[0].shape)
    # scaled = ms @ scale[0].cuda()
    # print((((x_2d_projected[0] - x_2d[0])**2).unsqueeze(-1) @ scale[0]).shape)
    energy = torch.stack(
        [(x_proj - x_gt)**2 * s.cuda() for x_proj, x_gt, s in zip(x_2d_projected, x_2d, scale)], dim=0
    )

    # occlusion_mask = torch.ones_like(energy)
    # occlusion_mask[..., 16:240, :, :] = 0
    #
    # energy = energy * occlusion_mask

    energy = energy.mean(-1).mean(-1).sum(-1).sum(0)

    return {
        "train": energy,
    }


def heatmap_energy(x_sample, heatmap, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)

    def batch_jacobian(f, x):
        f_sum = lambda x: torch.sum(f(x), axis=0)
        return torch.autograd.functional.jacobian(f_sum, x).permute(1, 2, 0)

    jacobioan = batch_jacobian(camera.proj2D, x_sample.squeeze()[1:, :])

    x_2d_projected = camera.proj2D(x_sample)

    heatmap = heatmap - heatmap.min() + 1e-6
    nll = -torch.log(heatmap)

    plt.imshow(nll.sum(dim=(0, 1)).detach().cpu().numpy())
    plt.colorbar()
    plt.savefig("dx.png")
    plt.close()

    dx = torch.stack(torch.gradient(nll, dim=(1, 2)), dim=-1)

    x_int = (x_2d_projected * 500 + 500).round().long()
    x_int = x_int[:, :, 1:]  # drop the hip keypoint
    x_int = x_int.clamp_(0, 999)

    update = dx[0, torch.arange(16), x_int[..., 0], x_int[..., 1]]

    print(update.mean())

    # tensor dot between jacobian and update (jacobian is 16x2x3, update is 16x2) -> 16x3
    update = jacobioan @ update.squeeze().unsqueeze(-1)
    update = update.squeeze()
    # add zeros for the hip keypoint
    update = torch.cat([torch.zeros_like(update[:1]), update], dim=0)

    return {
        "train": update,
    }


def learned_2d_energy(x_sample, x_2d, center, camera, **kwargs) -> Energy:
    """
    Energy function for conditioning on a monocular 2D pose.
    :param x_sample: The 3D pose sample generated by the model.
    :param x_2d: The 2D pose.
    :param center: The center of the 3D pose.
    :param camera: The camera used to project the 3D pose.
    :return: The energy of the sample.
    """
    x_sample = x_sample  # - center.unsqueeze(0).permute(0, 1, 3, 2)
    x_sample = x_sample.permute(0, 3, 1, 2)
    x_2d_projected = proj(x_sample)

    # print(x_2d.shape)
    x_2d = x_2d - x_2d[:, 0:1, :, :]
    _x_2d = x_2d.permute(0, 3, 1, 2).clone()

    energy = ((x_2d_projected - _x_2d) ** 2).mean(-1).mean(-1).sum(-1)

    # print(energy)

    return {
        "train": energy,
    }


def inpaint_2d_energy(x_sample, x_2d, center, **kwargs):
    return {
        "input_2D": x_2d + center.unsqueeze(0).permute(0, 1, 3, 2)[..., [0, 1], :],
    }


def inpaint_3d_energy(x_sample, x_3d, **kwargs):
    return {"train": x_3d}  # .repeat(5, 1, 1, 1)


energies = {
    "monocular": monocular_2d_energy,
    "monocular_2_cams": monocular_2d_energy_two_cams,
    "multi_view": multi_view,
    "gaussian": gaussian_2d_energy,
    "full_gaussian": full_gaussian_2d_energy,
    "w_monocular": w_monocular_2d_energy,
    "heatmap": heatmap_energy,
    "learned": learned_2d_energy,
    "inpaint": inpaint_2d_energy,
    "inpaint_3d": inpaint_3d_energy,
}
